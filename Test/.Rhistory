data$residuals <- data$y - data$predicted
# Creare il grafico
ggplot(data, aes(x = x, y = y)) +
geom_point() + # Punti
geom_smooth(method = "lm", se = FALSE, color = "blue") + # Linea di regressione
geom_segment(aes(xend = x, yend = predicted), color = "red", linetype = "dashed") + # Linee degli errori
labs(title = "Grafico della Regressione Lineare",
subtitle = "Con punti di dati, linea di regressione e linee degli errori",
x = "Variabile X",
y = "Variabile Y") +
theme_minimal()
# Caricare i pacchetti
library(ggplot2)
library(dplyr)
# Generare un dataset di esempio
set.seed(123)
n <- 20
x <- runif(n, 0, 10)
y <-   1.5 * x
# Creare un data frame con i dati
data <- data.frame(x = x, y = y)
# Fit del modello di regressione lineare
model <- lm(y ~ x, data = data)
# Prevedere i valori sulla base del modello
data$predicted <- predict(model)
# Calcolare gli errori (residui)
data$residuals <- data$y - data$predicted
# Creare il grafico
ggplot(data, aes(x = x, y = y)) +
geom_point() + # Punti
geom_smooth(method = "lm", se = FALSE, color = "blue") + # Linea di regressione
geom_segment(aes(xend = x, yend = predicted), color = "red", linetype = "dashed") + # Linee degli errori
labs(title = "Grafico della Regressione Lineare",
subtitle = "Con punti di dati, linea di regressione e linee degli errori",
x = "Variabile X",
y = "Variabile Y") +
theme_minimal()
# Caricare i pacchetti
library(ggplot2)
library(dplyr)
# Generare un dataset di esempio
set.seed(123)
n <- 20
x <- runif(n, 0, 10)
y <-   1.5 * x + rnorm(n, sd = 3)
# Creare un data frame con i dati
data <- data.frame(x = x, y = y)
# Fit del modello di regressione lineare
model <- lm(y ~ x, data = data)
# Prevedere i valori sulla base del modello
data$predicted <- predict(model)
# Calcolare gli errori (residui)
data$residuals <- data$y - data$predicted
# Creare il grafico
ggplot(data, aes(x = x, y = y)) +
geom_point() + # Punti
geom_smooth(method = "lm", se = FALSE, color = "blue") + # Linea di regressione
geom_segment(aes(xend = x, yend = predicted), color = "red", linetype = "dashed") + # Linee degli errori
labs(title = "Grafico della Regressione Lineare",
subtitle = "Con punti di dati, linea di regressione e linee degli errori",
x = "Variabile X",
y = "Variabile Y") +
theme_minimal()
# Caricare i pacchetti
library(ggplot2)
library(dplyr)
# Generare un dataset di esempio
set.seed(123)
n <- 20
x <- runif(n, 0, 10)
y <-   1.5 * x + rnorm(n, sd = 3)
# Creare un data frame con i dati
data <- data.frame(x = x, y = y)
# Fit del modello di regressione lineare
model <- lm(y ~ x, data = data)
# Prevedere i valori sulla base del modello
data$predicted <- predict(model)
# Calcolare gli errori (residui)
data$residuals <- data$y - data$predicted
# Creare il grafico
ggplot(data, aes(x = x, y = y)) +
geom_point() + # Punti
geom_smooth(method = "lm", se = FALSE, color = "blue") + # Linea di regressione
geom_segment(aes(xend = x, yend = predicted), color = "red", linetype = "dashed") + # Linee degli errori
labs(title = "Grafico della Regressione Lineare",
subtitle = "Con punti di dati, linea di regressione e linee degli errori",
x = "Variabile X",
y = "Variabile Y") +
theme_minimal()
# Caricare i pacchetti
library(ggplot2)
library(dplyr)
# Generare un dataset di esempio
set.seed(0)
n <- 20
x <- runif(n, 0, 10)
y <-   1.5 * x + rnorm(n, sd = 3)
# Creare un data frame con i dati
data <- data.frame(x = x, y = y)
# Fit del modello di regressione lineare
model <- lm(y ~ x, data = data)
# Prevedere i valori sulla base del modello
data$predicted <- predict(model)
# Calcolare gli errori (residui)
data$residuals <- data$y - data$predicted
# Creare il grafico
ggplot(data, aes(x = x, y = y)) +
geom_point() + # Punti
geom_smooth(method = "lm", se = FALSE, color = "blue") + # Linea di regressione
geom_segment(aes(xend = x, yend = predicted), color = "red", linetype = "dashed") + # Linee degli errori
labs(title = "Grafico della Regressione Lineare",
subtitle = "Con punti di dati, linea di regressione e linee degli errori",
x = "Variabile X",
y = "Variabile Y") +
theme_minimal()
# Caricare i pacchetti
library(ggplot2)
library(dplyr)
# Generare un dataset di esempio
set.seed(0)
n <- 20
x <- runif(n, 0, 10)
y <-   1.5 * x + rnorm(n, sd = 3)
# Creare un data frame con i dati
data <- data.frame(x = x, y = y)
# Fit del modello di regressione lineare
model <- lm(y ~ x, data = data)
# Prevedere i valori sulla base del modello
data$predicted <- predict(model)
# Calcolare gli errori (residui)
data$residuals <- data$y - data$predicted
# Creare il grafico
ggplot(data, aes(x = x, y = y)) +
geom_point() + # Punti
geom_smooth(method = "lm", se = FALSE, color = "blue") + # Linea di regressione
geom_segment(aes(xend = x, yend = predicted), color = "red", linetype = "dashed") + # Linee degli errori
labs(title = "Grafico della Regressione Lineare",
subtitle = "Con punti di dati, linea di regressione e linee degli errori",
x = "Variabile X",
y = "Variabile Y") +
theme_minimal()
# Caricare i pacchetti
library(ggplot2)
library(dplyr)
# Generare un dataset di esempio
set.seed(1)
n <- 20
x <- runif(n, 0, 10)
y <-   1.5 * x + rnorm(n, sd = 3)
# Creare un data frame con i dati
data <- data.frame(x = x, y = y)
# Fit del modello di regressione lineare
model <- lm(y ~ x, data = data)
# Prevedere i valori sulla base del modello
data$predicted <- predict(model)
# Calcolare gli errori (residui)
data$residuals <- data$y - data$predicted
# Creare il grafico
ggplot(data, aes(x = x, y = y)) +
geom_point() + # Punti
geom_smooth(method = "lm", se = FALSE, color = "blue") + # Linea di regressione
geom_segment(aes(xend = x, yend = predicted), color = "red", linetype = "dashed") + # Linee degli errori
labs(title = "Grafico della Regressione Lineare",
subtitle = "Con punti di dati, linea di regressione e linee degli errori",
x = "Variabile X",
y = "Variabile Y") +
theme_minimal()
# Caricare i pacchetti
library(ggplot2)
library(dplyr)
# Generare un dataset di esempio
set.seed(2)
n <- 20
x <- runif(n, 0, 10)
y <-   1.5 * x + rnorm(n, sd = 3)
# Creare un data frame con i dati
data <- data.frame(x = x, y = y)
# Fit del modello di regressione lineare
model <- lm(y ~ x, data = data)
# Prevedere i valori sulla base del modello
data$predicted <- predict(model)
# Calcolare gli errori (residui)
data$residuals <- data$y - data$predicted
# Creare il grafico
ggplot(data, aes(x = x, y = y)) +
geom_point() + # Punti
geom_smooth(method = "lm", se = FALSE, color = "blue") + # Linea di regressione
geom_segment(aes(xend = x, yend = predicted), color = "red", linetype = "dashed") + # Linee degli errori
labs(title = "Grafico della Regressione Lineare",
subtitle = "Con punti di dati, linea di regressione e linee degli errori",
x = "Variabile X",
y = "Variabile Y") +
theme_minimal()
# Caricare i pacchetti
library(ggplot2)
library(dplyr)
# Generare un dataset di esempio
set.seed(3)
n <- 20
x <- runif(n, 0, 10)
y <-   1.5 * x + rnorm(n, sd = 3)
# Creare un data frame con i dati
data <- data.frame(x = x, y = y)
# Fit del modello di regressione lineare
model <- lm(y ~ x, data = data)
# Prevedere i valori sulla base del modello
data$predicted <- predict(model)
# Calcolare gli errori (residui)
data$residuals <- data$y - data$predicted
# Creare il grafico
ggplot(data, aes(x = x, y = y)) +
geom_point() + # Punti
geom_smooth(method = "lm", se = FALSE, color = "blue") + # Linea di regressione
geom_segment(aes(xend = x, yend = predicted), color = "red", linetype = "dashed") + # Linee degli errori
labs(title = "Grafico della Regressione Lineare",
subtitle = "Con punti di dati, linea di regressione e linee degli errori",
x = "Variabile X",
y = "Variabile Y") +
theme_minimal()
# Caricare i pacchetti
library(ggplot2)
library(dplyr)
# Generare un dataset di esempio
set.seed(3)
n <- 10
x <- runif(n, 0, 10)
y <-   1.5 * x + rnorm(n, sd = 3)
# Creare un data frame con i dati
data <- data.frame(x = x, y = y)
# Fit del modello di regressione lineare
model <- lm(y ~ x, data = data)
# Prevedere i valori sulla base del modello
data$predicted <- predict(model)
# Calcolare gli errori (residui)
data$residuals <- data$y - data$predicted
# Creare il grafico
ggplot(data, aes(x = x, y = y)) +
geom_point() + # Punti
geom_smooth(method = "lm", se = FALSE, color = "blue") + # Linea di regressione
geom_segment(aes(xend = x, yend = predicted), color = "red", linetype = "dashed") + # Linee degli errori
labs(title = "Grafico della Regressione Lineare",
subtitle = "Con punti di dati, linea di regressione e linee degli errori",
x = "Variabile X",
y = "Variabile Y") +
theme_minimal()
# Caricare i pacchetti
library(ggplot2)
library(dplyr)
# Generare un dataset di esempio
set.seed(123)
n <- 10
x <- runif(n, 0, 10)
y <-   1.5 * x + rnorm(n, sd = 3)
# Creare un data frame con i dati
data <- data.frame(x = x, y = y)
# Fit del modello di regressione lineare
model <- lm(y ~ x, data = data)
# Prevedere i valori sulla base del modello
data$predicted <- predict(model)
# Calcolare gli errori (residui)
data$residuals <- data$y - data$predicted
# Creare il grafico
ggplot(data, aes(x = x, y = y)) +
geom_point() + # Punti
geom_smooth(method = "lm", se = FALSE, color = "blue") + # Linea di regressione
geom_segment(aes(xend = x, yend = predicted), color = "red", linetype = "dashed") + # Linee degli errori
labs(title = "Grafico della Regressione Lineare",
subtitle = "Con punti di dati, linea di regressione e linee degli errori",
x = "Variabile X",
y = "Variabile Y") +
theme_minimal()
# Caricare i pacchetti
library(ggplot2)
library(dplyr)
# Generare un dataset di esempio
set.seed(100)
n <- 10
x <- runif(n, 0, 10)
y <-   1.5 * x + rnorm(n, sd = 3)
# Creare un data frame con i dati
data <- data.frame(x = x, y = y)
# Fit del modello di regressione lineare
model <- lm(y ~ x, data = data)
# Prevedere i valori sulla base del modello
data$predicted <- predict(model)
# Calcolare gli errori (residui)
data$residuals <- data$y - data$predicted
# Creare il grafico
ggplot(data, aes(x = x, y = y)) +
geom_point() + # Punti
geom_smooth(method = "lm", se = FALSE, color = "blue") + # Linea di regressione
geom_segment(aes(xend = x, yend = predicted), color = "red", linetype = "dashed") + # Linee degli errori
labs(title = "Grafico della Regressione Lineare",
subtitle = "Con punti di dati, linea di regressione e linee degli errori",
x = "Variabile X",
y = "Variabile Y") +
theme_minimal()
# Caricare i pacchetti
library(ggplot2)
library(dplyr)
# Generare un dataset di esempio
set.seed(101)
n <- 10
x <- runif(n, 0, 10)
y <-   1.5 * x + rnorm(n, sd = 3)
# Creare un data frame con i dati
data <- data.frame(x = x, y = y)
# Fit del modello di regressione lineare
model <- lm(y ~ x, data = data)
# Prevedere i valori sulla base del modello
data$predicted <- predict(model)
# Calcolare gli errori (residui)
data$residuals <- data$y - data$predicted
# Creare il grafico
ggplot(data, aes(x = x, y = y)) +
geom_point() + # Punti
geom_smooth(method = "lm", se = FALSE, color = "blue") + # Linea di regressione
geom_segment(aes(xend = x, yend = predicted), color = "red", linetype = "dashed") + # Linee degli errori
labs(title = "Grafico della Regressione Lineare",
subtitle = "Con punti di dati, linea di regressione e linee degli errori",
x = "Variabile X",
y = "Variabile Y") +
theme_minimal()
# Caricare i pacchetti
library(ggplot2)
library(dplyr)
# Generare un dataset di esempio
set.seed(101)
n <- 10
x <- runif(n, 0, 10)
y <-   1.5 * x + rnorm(n, sd = 3)
# Creare un data frame con i dati
data <- data.frame(x = x, y = y)
# Fit del modello di regressione lineare
model <- lm(y ~ x, data = data)
# Prevedere i valori sulla base del modello
data$predicted <- predict(model)
# Calcolare gli errori (residui)
data$residuals <- data$y - data$predicted
# Creare il grafico
ggplot(data, aes(x = x, y = y)) +
geom_point() + # Punti
geom_smooth(method = "lm", se = FALSE, color = "blue") + # Linea di regressione
geom_segment(aes(xend = x, yend = predicted), color = "red", linetype = "dashed") + # Linee degli errori
theme_minimal()
lm(y ~ x, data = data)
View(data)
View(data)
lm(y ~ x)
# Installare e caricare ggplot2
library(ggplot2)
# Installare e caricare ggplot2
library(ggplot2)
# Generare un dataset di esempio
set.seed(123)
x <- runif(50, 0, 10)
y <- 5 + rnorm(50, sd = 3)  # y non dipende da x, quindi β1 = 0
# Creare un data frame con i dati
data <- data.frame(x = x, y = y)
# Creare il grafico
ggplot(data, aes(x = x, y = y)) +
geom_point() + # Punti
geom_hline(yintercept = mean(y), color = "blue", linetype = "dashed") + # Linea media
labs(title = "Esempio di Regressione Lineare con Coefficiente Angolare 0",
subtitle = "Nessuna correlazione tra la variabile indipendente e la risposta",
x = "Variabile X",
y = "Variabile Y") +
theme_minimal()
# Caricare i pacchetti
library(ggplot2)
library(dplyr)
# Generare un dataset di esempio
set.seed(101)
n <- 10
x <- runif(n, 0, 10)
y <-   1.5 * x + rnorm(n, sd = 3)
# Creare un data frame con i dati
data <- data.frame(x = x, y = y)
# Fit del modello di regressione lineare
model <- lm(y ~ x, data = data)
# Prevedere i valori sulla base del modello
data$predicted <- predict(model)
# Calcolare gli errori (residui)
data$residuals <- data$y - data$predicted
# Creare il grafico
ggplot(data, aes(x = x, y = y)) +
geom_point() + # Punti
geom_smooth(method = "lm", se = FALSE, color = "blue") + # Linea di regressione
geom_segment(aes(xend = x, yend = predicted), color = "red", linetype = "dashed") + # Linee degli errori
theme_minimal()
# Installare e caricare ggplot2
library(ggplot2)
# Generare un dataset di esempio
set.seed(123)
x <- runif(50, 0, 10)
y <- 5 + rnorm(50, sd = 3)  # y non dipende da x, quindi β1 = 0
# Creare un data frame con i dati
data <- data.frame(x = x, y = y)
# Creare il grafico
ggplot(data, aes(x = x, y = y)) +
geom_point() + # Punti
geom_hline(yintercept = mean(y), color = "blue", linetype = "dashed") + # Linea media
labs(title = "Esempio di Regressione Lineare con Coefficiente Angolare 0",
subtitle = "Nessuna correlazione tra la variabile indipendente e la risposta",
x = "Variabile X",
y = "Variabile Y") +
theme_minimal()
pbinom(q=5, 10, prob = 0.2)
dbinom(x=5, 10, prob = 0.2)
qbinom(p=9/10,prob=2/3)
qbinom(p=9/10,size=1,prob=2/3)
qbinom(p=9/10,size=10,prob=2/3)
qbinom(p=9/10,size=100,prob=2/3)
qbinom(p=9/10,size=100,prob=2/3)
dbinom(x=0, size=1, prob=2/3)
1-dbinom(x=0, size=1, prob=2/3)
1-dbinom(x=0, size=10, prob=2/3)
1-dbinom(x=0, size=7, prob=2/3)
1-dbinom(x=0, size=5, prob=2/3)
1-dbinom(x=0, size=1, prob=2/3)
1-dbinom(x=0, size=2, prob=2/3)
1-dbinom(x=0, size=3, prob=2/3)
1-pbinom(q=0, size=3, prob=2/3)
1-pbinom(q=0, size=2, prob=2/3)
1-pbinom(q=0, size=2, prob=2/3)
qbinom(p=0.0)
qbinom(p=0.1, size=10, prob=2/3)
qbinom(p=0.1, size=100, prob=2/3)
qbinom(p=0.9, size=7, prob=2/3)
qbinom(p=0.9, size=6, prob=2/3)
qbinom(p=0.9, size=6, prob=2/3)
1-pbinom(q=0, size=7, prob=2/3)
1-pbinom(q=0, size=6, prob=2/3)
1-pbinom(q=0, size=5, prob=2/3)
1-pbinom(q=0, size=3, prob=2/3)
1-pbinom(q=0, size=2, prob=2/3)
1-pbinom(q=0, size=3, prob=2/3)
pbinom(q=0, size=3, prob=2/3, lower.tail = FALSE)
pbinom(q=0, size=2, prob=2/3, lower.tail = FALSE)
pbinom(q=0, size=2, prob=2/3, lower.tail = FALSE)
dbinom(x=3, size=5, prob = 2/3)
dbinom(x=3, size=5, prob = 2/3)/2
dbinom(x=4, size=10, prob = 0.3) + dbinom(x=5, size=10, prob = 0.3) + dbinom(x=6, size=10, prob = 0.3)
pbinom(q=19, size=24, prob = 0.6, lower.tail = FALSE)
pbinom(q=2, size=24, prob = 0.03)
pbinom(q=2, size=30, prob = 0.03)
pbinom(q=2, size=30, prob = 0.03, lower.tail = FALSE)
pbinom(q=2, size=30, prob = 0.03)
dbinom(q=0, size=30, prob = 0.03) + dbinom(q=1, size=30, prob = 0.03) + dbinom(q=2, size=30, prob = 0.03)
dbinom(x=0, size=30, prob = 0.03) + dbinom(x=1, size=30, prob = 0.03) + dbinom(x=2, size=30, prob = 0.03)
1-(dbinom(x=0, size=30, prob = 0.03) + dbinom(x=1, size=30, prob = 0.03) + dbinom(x=2, size=30, prob = 0.03))
prob <- pbinom(2, size = 30, prob = 0.03)
prob
1-prob
dpois(5,5*3.3)
prob <- dpois(5, 3.33)
prob
ppois(q=30, lambda = 18) - ppois(q=10, lambda = 18)
pbinom(q=30, size=60, prob=0.3) - pbinom(q=10, size=60, prob=0.3)
pbinom(q=30, size=60, prob=0.3) - pbinom(q=9, size=60, prob=0.3)
pbinom(q=30, size=60, prob=0.3) - pbinom(q=11, size=60, prob=0.3)
pbinom(q=30, size=60, prob=0.3) - pbinom(q=10, size=60, prob=0.3)
pbinom(q=79, size=100, prob=0.75, lower.tail = FALSE)
pbinom(q=79, size=100, prob=0.75, lower.tail = TRUE)
pbinom(q=80, size=100, prob=0.75, lower.tail = FALSE)
pbinom(q=79, size=100, prob=0.75, lower.tail = FALSE)
# Definire i parametri
n <- 100       # Numero totale di studenti che superano l'esame di ammissione
p <- 0.75      # Probabilità di iscrizione
# Calcolare la probabilità cumulativa di avere al massimo 80 iscritti
prob_cum <- pbinom(80, size = n, prob = p)
# Calcolare la probabilità complementare
prob <- 1 - prob_cum
# Visualizzare il risultato
prob
ppois(q=2, lambda = 1.5)
1-ppois(q=2, lambda = 1.5)
ppois(q=3, lambda = 3)
ppois(q=44, lambda = 6)
ppois(q=4, lambda = 6)
ppois(q=3, lambda = 6)
1-ppois(q=2, lambda = 1)
pnorm(q=0.75, lower.tail = FALSE)
pnorm(q=2, mean=24, sd=4,lower.tail = FALSE)
pnorm(q=22, mean=24, sd=4,lower.tail = FALSE)
pnorm(q=180, mean=170, sd=10,lower.tail = TRUE) - pnorm(q=155, mean=170, sd=10,lower.tail = TRUE)
data <- c(0,1,2,3,4,5,6)
quantile(data)
4.5-1.5
1-pbinom((q=1, size=10, prob=0.01)
1 - pbinom((q=1, size=10, prob=0.01)
1 - pbinom(q=1, size=10, prob=0.01)
pnorm(q=7, mean=163, sd=7) - (1-pnorm(q=-7, mean=163, sd=7))
pnorm(q=7, mean=163, sd=7) - (1 - pnorm(q=-7, mean=163, sd=7))
pnorm(q=7, mean=163, sd=7)
pnorm(q=22.28)
pnorm(q=15ù)
pnorm(q=15)
pnorm(q=10)
pnorm(q=1) - (1-qnorm(q=-1))
pnorm(q=1) - (1-pnorm(q=-1))
pnorm(q=1)
pnorm(q=-1)
pnorm(q=1) - (1-pnorm(q=1))
pnorm(q=2) - (1-pnorm(q=2))
pnorm(q=3) - (1-pnorm(q=3))
data <- c(2.75 2.62 2.74 3.85
data <- c(2.75, 2.62, 2.74, 3.85, 2.34, 2.74, 3.93, 4.21, 3.88, 4.33, 3.46, 4.52, 2.43, 3.65, 2.78, 3.56, 3.01)
mean(data)
sd(data)
var(data)
median(data)
